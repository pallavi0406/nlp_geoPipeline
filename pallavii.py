# -*- coding: utf-8 -*-
"""pallavii.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FIied9blZkQTPI33wj0Hgu9UiXPq2VfT
"""

!pip install pandas spacy geopy transformers sumy rouge-score torch sentencepiece

!python -m spacy download en_core_web_sm

import pandas as pd
import spacy
from geopy.geocoders import Nominatim
from transformers import pipeline
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer

# Change path to your dataset location
file_path = "/content/train.csv"

# Load dataset with error handling
df = pd.read_csv(file_path, encoding="latin1", on_bad_lines="skip", engine="python")

# Keep only useful columns
df = df[['article', 'highlights']]
df = df.dropna().reset_index(drop=True)

print("Dataset shape:", df.shape)
print(df.head(2))

nlp = spacy.load("en_core_web_sm")

# Load abstractive summarizer (T5-small)
summarizer = pipeline("summarization", model="t5-small", tokenizer="t5-small")

# Initialize geocoder
geolocator = Nominatim(user_agent="geo_summarizer")

def textrank_summary(text, sentence_count=3):
    parser = PlaintextParser.from_string(text, Tokenizer("english"))
    summarizer_textrank = TextRankSummarizer()
    summary = summarizer_textrank(parser.document, sentence_count)
    return " ".join([str(sentence) for sentence in summary])

# Abstractive (T5-small)
def t5_summary(text, max_len=100, min_len=30):
    summary = summarizer(text, max_length=max_len, min_length=min_len, do_sample=False)
    return summary[0]['summary_text']

def extract_locations(text):
    doc = nlp(text)
    locations = [ent.text for ent in doc.ents if ent.label_ == "GPE"]
    return list(set(locations))

# Convert place â†’ coordinates
def geocode_location(location):
    try:
        loc = geolocator.geocode(location)
        if loc:
            return (loc.latitude, loc.longitude)
    except:
        return None

def process_article(article, method="t5"):
    # Summarization
    if method == "textrank":
        summary = textrank_summary(article, sentence_count=3)
    else:
        summary = t5_summary(article)

    # Geo-tagging
    locations = extract_locations(article)
    coords = [(loc, geocode_location(loc)) for loc in locations if geocode_location(loc)]

    return summary, coords

results = []

# Test only on first 5 articles (for speed)
for i in range(5):
    article = df['article'][i]
    summary, geo_info = process_article(article, method="t5")  # change to "textrank" if needed

    for loc, coord in geo_info:
        results.append({
            "Article_ID": i,
            "Summary": summary,
            "Location": loc,
            "Latitude": coord[0],
            "Longitude": coord[1]
        })

output_df = pd.DataFrame(results)
output_df.to_csv("summaries_with_geotags.csv", index=False)
print(output_df.head())

from rouge_score import rouge_scorer

scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)

ref = df['highlights'][0]   # reference summary
art = df['article'][0]
pred_summary, _ = process_article(art, method="t5")

score = scorer.score(ref, pred_summary)
print("ROUGE Score:", score)